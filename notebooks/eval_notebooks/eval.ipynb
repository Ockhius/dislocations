{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "unet\n",
      "=> loaded checkpoint '/home/dagnyt/EPFL/dislocations/models/dislocations_segmentation/150_segmentor.tar' (epoch 150)\n",
      "=> loaded checkpoint '/home/dagnyt/EPFL/dislocations/models/dislocations_segmentation/150_segmentor.tar' (epoch 150)\n",
      "scmnet\n",
      "=> loaded checkpoint '/home/dagnyt/EPFL/dislocations/models/models_2020_04/dislocations_matching_disp_warp_var_joint_10addaug/150_scmnet_light.tar' (epoch 150)\n"
     ]
    }
   ],
   "source": [
    "config_file = 'delineation/configs/dislocation_matching_disp_and_warp_and var_home.yml'\n",
    "aug_config_file = 'delineation/configs/aug.yml'\n",
    "import torch\n",
    "from delineation.configs.defaults_segmentation import _C as cfg\n",
    "from delineation.datasets import make_data_loader\n",
    "from delineation.models import build_model_list\n",
    "from delineation.utils import settings, cost_volume_helpers\n",
    "from delineation.utils.settings import evaluate_results\n",
    "\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import yaml\n",
    "\n",
    "cfg.merge_from_file(config_file)\n",
    "with open(aug_config_file, 'r') as ymlfile:\n",
    "    cfg_aug = yaml.load(aug_config_file)\n",
    "\n",
    "_device = settings.initialize_cuda_and_logging(cfg)  # '_device' is GLOBAL VAR\n",
    "\n",
    "train_loader, val_loader = make_data_loader(cfg, cfg_aug)\n",
    "seg_model, model = build_model_list(cfg, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1116_1116 DPC DF4 71.0 kx DF4-B_LEFT.png',)\n",
      "0.35424354243542433 0.012076484401207649 0.0 0.8679565 tensor(-4., device='cuda:0') tensor(2., device='cuda:0')\n",
      "('1123_1123 DPC DF4 71.0 kx DF4-B_LEFT.png',)\n",
      "0.4160292650482208 0.06484868639840373 0.0 1.1003114 tensor(0., device='cuda:0') tensor(7., device='cuda:0')\n",
      "('2019-12-02_TiAl_box3n15_zoom_1_2_Aligned_9_of_90001_LEFT.png',)\n",
      "0.4091642465311391 0.052436269764440144 0.007018393030009681 1.084209 tensor(-4., device='cuda:0') tensor(5., device='cuda:0')\n",
      "('2019-12-02_TiAl_box3n15_zoom_4_3_Aligned_9_of_90003_LEFT.png',)\n",
      "0.4355902219363139 0.06794789321325186 0.02203280797684143 1.2023383 tensor(-11., device='cuda:0') tensor(9., device='cuda:0')\n",
      "('2019-12-02_TiAl_box3n15_zoom_7_5_Aligned_9_of_90007_LEFT.png',)\n",
      "0.5191446657403119 0.18550254747568318 0.07410838351088467 1.8061295 tensor(-10., device='cuda:0') tensor(12., device='cuda:0')\n",
      "('2019-12-02_TiAl_box3n15_zoom_7_6_Aligned_9_of_90006_LEFT.png',)\n",
      "0.3945950167929392 0.03202374443489807 0.0 1.0230206 tensor(-6., device='cuda:0') tensor(5., device='cuda:0')\n",
      "('2507 5 2BC5 ZA3 mag OA20_2507 5 2BC5 ZA3 mag OA20-2_LEFT.png',)\n",
      "0.5611168332266236 0.14455919605823567 0.03326559585780697 1.6235498 tensor(-1., device='cuda:0') tensor(4., device='cuda:0')\n",
      "('TiAl_box3n15_pairs_0_16_img_16_LEFT.png',)\n",
      "0.8358290866326931 0.6453939631517052 0.573657389259114 14.612373 tensor(-51., device='cuda:0') tensor(25., device='cuda:0')\n",
      "('TiAl_box3n15_pairs_0_2_img_2_LEFT.png',)\n",
      "0.6486242670275146 0.19365508946023155 0.061795218764095626 1.8740304 tensor(-10., device='cuda:0') tensor(5., device='cuda:0')\n",
      "('TiAl_box3n15_pairs_0_4_img_4_LEFT.png',)\n",
      "0.5964202800868719 0.20519733393244963 0.1324047030629821 2.1326778 tensor(-13., device='cuda:0') tensor(8., device='cuda:0')\n",
      "('TiAl_box3n15_pairs_0_7_img_7_LEFT.png',)\n",
      "0.6704054566123532 0.3323986358469117 0.22720727548313754 3.625667 tensor(-22., device='cuda:0') tensor(11., device='cuda:0')\n",
      "('TiAl_box3n15_pairs_n2_2_img_2_LEFT.png',)\n",
      "0.7645466847090663 0.4264020448052924 0.28101037437979254 4.0886316 tensor(-17., device='cuda:0') tensor(15., device='cuda:0')\n",
      "('TiAl_box3n15_pairs_n4_4_img_4_LEFT.png',)\n",
      "0.6595521605631693 0.3230734666367108 0.21553209016700367 3.6600869 tensor(-10., device='cuda:0') tensor(17., device='cuda:0')\n",
      "('ant2_ant2-B_LEFT.png',)\n",
      "0.36407854440641324 0.04467663484056927 0.02504053323725455 1.07338 tensor(-2., device='cuda:0') tensor(7., device='cuda:0')\n",
      "('ant_ant-B_LEFT.png',)\n",
      "0.386660365097182 0.052342411531872156 0.01742777810598452 1.0891765 tensor(-3., device='cuda:0') tensor(5., device='cuda:0')\n",
      "('pairs_18_20_GaN - TiltAxis is almost vertical_0018_LEFT.png',)\n",
      "0.23791478902089308 0.006759524784924211 0.00010241704219582139 0.6930952 tensor(-1., device='cuda:0') tensor(4., device='cuda:0')\n",
      "here\n",
      "Mean per dataset: 0.5158697141166956, 0.17433087042104922, 0.10441268499231894, 2.5972896218299866\n"
     ]
    }
   ],
   "source": [
    "seg_model.eval()\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "pix1_err_m, pix3_err_m, pix5_err_m, epe_m, count = 0, 0, 0, 0, 0\n",
    "\n",
    "for batch_idx, (l, r, lgt, rgt, dlgt, l_name) in (enumerate(val_loader)):\n",
    "        indices = cost_volume_helpers.volume_indices(2 * cfg.TRAINING.MAXDISP, len(l),\n",
    "                                                     cfg.TRAINING.HEIGHT, cfg.TRAINING.WIDTH, _device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            l, r, lgt, rgt, dlgt = l.to(_device), r.to(_device), lgt.to(_device), rgt.to(_device), dlgt.to(_device)\n",
    "\n",
    "            l_seg, l_segmap = seg_model(l)\n",
    "            r_seg, r_segmap = seg_model(r)\n",
    "            if abs(dlgt.max()>32) or abs(dlgt.min()>32):\n",
    "                continue\n",
    "            print(l_name)\n",
    "            dl_scores = model(l_segmap, r_segmap)\n",
    "            \n",
    "            dl_ = F.softmax(-dl_scores, 2)\n",
    "            dl = torch.sum(dl_.mul(indices), 2) - cfg.TRAINING.MAXDISP\n",
    "            for i in range(0, len(dlgt)):\n",
    "                pix1_err, pix3_err, pix5_err, epe = evaluate_results(dlgt[i], dl[i], lgt[i])\n",
    "                print(pix1_err, pix3_err, pix5_err, epe, dlgt.min(), dlgt.max())\n",
    "                pix1_err_m += pix1_err\n",
    "                pix3_err_m += pix3_err\n",
    "                pix5_err_m += pix5_err\n",
    "                epe_m += epe\n",
    "                count += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "print('here')\n",
    "values = pix1_err_m / count, pix3_err_m / count, pix5_err_m / count, epe_m / count\n",
    "print('Mean per dataset: {}, {}, {}, {}'.format(pix1_err_m / count, pix3_err_m / count, pix5_err_m / count, epe_m / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast",
   "language": "python",
   "name": "fast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
