{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "unet\n",
      "=> loaded checkpoint '/home/dagnyt/EPFL/dislocations/models/dislocations_segmentation/150_segmentor.tar' (epoch 150)\n",
      "=> loaded checkpoint '/home/dagnyt/EPFL/dislocations/models/models_2020_04/dislocations_matching_disp_warp_var_joint_10addaug/150_seg.tar' (epoch 150)\n",
      "scmnet\n",
      "=> loaded checkpoint '/home/dagnyt/EPFL/dislocations/models/models_2020_04/dislocations_matching_disp_warp_var_joint_10addaug/150_scmnet_light.tar' (epoch 150)\n"
     ]
    }
   ],
   "source": [
    "config_file = 'delineation/configs/dislocation_matching_disp_and_warp_and var_home.yml'\n",
    "aug_config_file = 'delineation/configs/aug.yml'\n",
    "import torch\n",
    "from delineation.configs.defaults_segmentation import _C as cfg\n",
    "from delineation.datasets import make_data_loader\n",
    "from delineation.models import build_model_list\n",
    "from delineation.utils import settings, cost_volume_helpers\n",
    "from delineation.utils.settings import evaluate_results\n",
    "\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import yaml\n",
    "\n",
    "cfg.merge_from_file(config_file)\n",
    "with open(aug_config_file, 'r') as ymlfile:\n",
    "    cfg_aug = yaml.load(aug_config_file)\n",
    "\n",
    "_device = settings.initialize_cuda_and_logging(cfg)  # '_device' is GLOBAL VAR\n",
    "\n",
    "train_loader, val_loader = make_data_loader(cfg, cfg_aug)\n",
    "seg_model, model = build_model_list(cfg, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2020_04_15_pair_0_1_SIFT_translation0001_LEFT.png',)\n",
      "0.5171343891821802 0.11067889228489396 0.01940353801982032 1.3559731 tensor(-15., device='cuda:0') tensor(6., device='cuda:0')\n",
      "('2020_04_15_pair_13_14_SIFT_translation0014_LEFT.png',)\n",
      "0.6111244162375763 0.24104897617051851 0.1429768889953299 2.8495824 tensor(-1., device='cuda:0') tensor(30., device='cuda:0')\n",
      "('2020_04_15_pair_14_15_SIFT_translation0015_LEFT.png',)\n",
      "0.6356679319211461 0.16872780702828455 0.06801763193339047 1.9047856 tensor(-19., device='cuda:0') tensor(12., device='cuda:0')\n",
      "('2020_04_15_pair_1_2_SIFT_translation0002_LEFT.png',)\n",
      "0.5661670038624241 0.1690270369689167 0.07637483906566121 1.8249056 tensor(-21., device='cuda:0') tensor(12., device='cuda:0')\n",
      "('2020_04_15_pair_3_4_SIFT_translation0003_LEFT.png',)\n",
      "0.5360410830999066 0.12450980392156863 0.011764705882352941 1.4326398 tensor(-9., device='cuda:0') tensor(10., device='cuda:0')\n",
      "('2020_04_15_pair_5_6_SIFT_translation0005_LEFT.png',)\n",
      "0.43586675600650904 0.04532401646405667 0.0021537283430649945 1.0935029 tensor(-7., device='cuda:0') tensor(7., device='cuda:0')\n",
      "('2020_04_15_pair_8_9_SIFT_translation0009_LEFT.png',)\n",
      "0.5418029632480277 0.07172407157975755 0.004521839522801616 1.3180246 tensor(-4., device='cuda:0') tensor(11., device='cuda:0')\n",
      "('2020_04_15_pair_9_10_SIFT_translation0009_LEFT.png',)\n",
      "0.4705118337502405 0.06051568212430248 0.02039638252838176 1.2515312 tensor(-14., device='cuda:0') tensor(7., device='cuda:0')\n",
      "here\n",
      "Mean per dataset: 0.5392895471635013, 0.12394453581778739, 0.0432011942863504, 1.6288681775331497\n"
     ]
    }
   ],
   "source": [
    "seg_model.eval()\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "pix1_err_m, pix3_err_m, pix5_err_m, epe_m, count = 0, 0, 0, 0, 0\n",
    "\n",
    "for batch_idx, (l, r, lgt, rgt, dlgt, l_name) in (enumerate(val_loader)):\n",
    "        indices = cost_volume_helpers.volume_indices(2 * cfg.TRAINING.MAXDISP, len(l),\n",
    "                                                     cfg.TRAINING.HEIGHT, cfg.TRAINING.WIDTH, _device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            l, r, lgt, rgt, dlgt = l.to(_device), r.to(_device), lgt.to(_device), rgt.to(_device), dlgt.to(_device)\n",
    "\n",
    "            l_seg, l_segmap = seg_model(l)\n",
    "            r_seg, r_segmap = seg_model(r)\n",
    "            if abs(dlgt.max()>32) or abs(dlgt.min()>32):\n",
    "                continue\n",
    "            print(l_name)\n",
    "            dl_scores = model(l_segmap, r_segmap)\n",
    "            \n",
    "            dl_ = F.softmax(-dl_scores, 2)\n",
    "            dl = torch.sum(dl_.mul(indices), 2) - cfg.TRAINING.MAXDISP\n",
    "            for i in range(0, len(dlgt)):\n",
    "                pix1_err, pix3_err, pix5_err, epe = evaluate_results(dlgt[i], dl[i], lgt[i])\n",
    "                print(pix1_err, pix3_err, pix5_err, epe, dlgt.min(), dlgt.max())\n",
    "                pix1_err_m += pix1_err\n",
    "                pix3_err_m += pix3_err\n",
    "                pix5_err_m += pix5_err\n",
    "                epe_m += epe\n",
    "                count += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "print('here')\n",
    "values = pix1_err_m / count, pix3_err_m / count, pix5_err_m / count, epe_m / count\n",
    "print('Mean per dataset: {}, {}, {}, {}'.format(pix1_err_m / count, pix3_err_m / count, pix5_err_m / count, epe_m / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast",
   "language": "python",
   "name": "fast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
